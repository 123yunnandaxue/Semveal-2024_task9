{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23697,"status":"ok","timestamp":1707404603094,"user":{"displayName":"Jie Wang","userId":"07776956424612082570"},"user_tz":-480},"id":"znJQ1OHrxr-u","outputId":"073b7294-b876-460f-db7e-492510d34969"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: dill, multiprocess, datasets\n","Successfully installed datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"]}],"source":["!pip install datasets\n","!pip install transformers\n","!pip install transformers accelerate evaluate datasets peft -q\n","!pip install --no-cache-dir transformers sentencepiece"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4393,"status":"ok","timestamp":1707404607466,"user":{"displayName":"Jie Wang","userId":"07776956424612082570"},"user_tz":-480},"id":"VX6utC44x1aP"},"outputs":[],"source":["from __future__ import print_function\n","\n","import torch\n","import torch.nn as nn\n","from transformers import DebertaV2PreTrainedModel, DebertaV2Model\n","from typing import Optional, Tuple, Union\n","\n","from transformers.modeling_outputs import MultipleChoiceModelOutput\n","from transformers.activations import ACT2FN\n","\n","class ContextPooler(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.dense = nn.Linear(config.pooler_hidden_size, config.pooler_hidden_size)\n","        self.dropout = StableDropout(config.pooler_dropout)\n","        self.config = config\n","\n","    def forward(self, hidden_states):\n","        # We \"pool\" the model by simply taking the hidden state corresponding\n","        # to the first token.\n","\n","        context_token = hidden_states[:, 0]\n","        context_token = self.dropout(context_token)\n","        pooled_output = self.dense(context_token)\n","        pooled_output = ACT2FN[self.config.pooler_hidden_act](pooled_output)\n","        return pooled_output\n","\n","    @property\n","    def output_dim(self):\n","        return self.config.hidden_size\n","\n","class StableDropout(nn.Module):\n","    \"\"\"\n","    Optimized dropout module for stabilizing the training\n","\n","    Args:\n","        drop_prob (float): the dropout probabilities\n","    \"\"\"\n","\n","    def __init__(self, drop_prob):\n","        super().__init__()\n","        self.drop_prob = drop_prob\n","        self.count = 0\n","        self.context_stack = None\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Call the module\n","\n","        Args:\n","            x (`torch.tensor`): The input tensor to apply dropout\n","        \"\"\"\n","        if self.training and self.drop_prob > 0:\n","            return XDropout.apply(x, self.get_context())\n","        return x\n","\n","    def clear_context(self):\n","        self.count = 0\n","        self.context_stack = None\n","\n","    def init_context(self, reuse_mask=True, scale=1):\n","        if self.context_stack is None:\n","            self.context_stack = []\n","        self.count = 0\n","        for c in self.context_stack:\n","            c.reuse_mask = reuse_mask\n","            c.scale = scale\n","\n","    def get_context(self):\n","        if self.context_stack is not None:\n","            if self.count >= len(self.context_stack):\n","                self.context_stack.append(DropoutContext())\n","            ctx = self.context_stack[self.count]\n","            ctx.dropout = self.drop_prob\n","            self.count += 1\n","            return ctx\n","        else:\n","            return self.drop_prob\n","\n","class DropoutContext(object):\n","    def __init__(self):\n","        self.dropout = 0\n","        self.mask = None\n","        self.scale = 1\n","        self.reuse_mask = True\n","\n","\n","# Copied from transformers.models.deberta.modeling_deberta.get_mask\n","def get_mask(input, local_context):\n","    if not isinstance(local_context, DropoutContext):\n","        dropout = local_context\n","        mask = None\n","    else:\n","        dropout = local_context.dropout\n","        dropout *= local_context.scale\n","        mask = local_context.mask if local_context.reuse_mask else None\n","\n","    if dropout > 0 and mask is None:\n","        mask = (1 - torch.empty_like(input).bernoulli_(1 - dropout)).to(torch.bool)\n","\n","    if isinstance(local_context, DropoutContext):\n","        if local_context.mask is None:\n","            local_context.mask = mask\n","\n","    return mask, dropout\n","class XDropout(torch.autograd.Function):\n","    \"\"\"Optimized dropout function to save computation and memory by using mask operation instead of multiplication.\"\"\"\n","\n","    @staticmethod\n","    def forward(ctx, input, local_ctx):\n","        mask, dropout = get_mask(input, local_ctx)\n","        ctx.scale = 1.0 / (1 - dropout)\n","        if dropout > 0:\n","            ctx.save_for_backward(mask)\n","            return input.masked_fill(mask, 0) * ctx.scale\n","        else:\n","            return input\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        if ctx.scale > 1:\n","            (mask,) = ctx.saved_tensors\n","            return grad_output.masked_fill(mask, 0) * ctx.scale, None\n","        else:\n","            return grad_output, None\n","\n","    @staticmethod\n","    def symbolic(g: torch._C.Graph, input: torch._C.Value, local_ctx: Union[float, DropoutContext]) -> torch._C.Value:\n","        from torch.onnx import symbolic_opset12\n","\n","        dropout_p = local_ctx\n","        if isinstance(local_ctx, DropoutContext):\n","            dropout_p = local_ctx.dropout\n","        # StableDropout only calls this function when training.\n","        train = True\n","        # TODO: We should check if the opset_version being used to export\n","        # is > 12 here, but there's no good way to do that. As-is, if the\n","        # opset_version < 12, export will fail with a CheckerError.\n","        # Once https://github.com/pytorch/pytorch/issues/78391 is fixed, do something like:\n","        # if opset_version < 12:\n","        #   return torch.onnx.symbolic_opset9.dropout(g, input, dropout_p, train)\n","        return symbolic_opset12.dropout(g, input, dropout_p, train)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1707404607466,"user":{"displayName":"Jie Wang","userId":"07776956424612082570"},"user_tz":-480},"id":"yF3LpXkRx1dT"},"outputs":[],"source":["def KL(input, target, reduction=\"sum\"):\n","    input = input.float()\n","    target = target.float()\n","    loss = F.kl_div(F.log_softmax(input, dim=-1, dtype=torch.float32),\n","                    F.softmax(target, dtype=torch.float32), reduction=reduction)\n","    return loss"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1707404607466,"user":{"displayName":"Jie Wang","userId":"07776956424612082570"},"user_tz":-480},"id":"7YQPn7lSYazn"},"outputs":[],"source":["class FocalLoss(nn.Module):\n","\n","    def __init__(self, weight=None, reduction='mean', gamma=0, eps=1e-7):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.eps = eps\n","        self.ce = torch.nn.CrossEntropyLoss(weight=weight, reduction=reduction)\n","\n","    def forward(self, input, target):\n","        logp = self.ce(input, target)\n","        p = torch.exp(-logp)\n","        loss = (1 - p) ** self.gamma * logp\n","        return loss.mean()"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1707404607466,"user":{"displayName":"Jie Wang","userId":"07776956424612082570"},"user_tz":-480},"id":"Tdg7nj-7x1f7"},"outputs":[],"source":["class DebertaV2ForMultipleChoice(DebertaV2PreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","\n","        num_labels = getattr(config, \"num_labels\", 2)\n","        self.num_labels = num_labels\n","\n","        self.deberta = DebertaV2Model(config)\n","        self.pooler = ContextPooler(config)\n","        output_dim = self.pooler.output_dim\n","\n","        self.classifier = nn.Linear(output_dim, 1)\n","        drop_out = getattr(config, \"cls_dropout\", None)\n","        drop_out = self.config.hidden_dropout_prob if drop_out is None else drop_out\n","        self.dropout = StableDropout(drop_out)\n","\n","        self.init_weights()\n","\n","    def get_input_embeddings(self):\n","        return self.deberta.get_input_embeddings()\n","\n","    def set_input_embeddings(self, new_embeddings):\n","        self.deberta.set_input_embeddings(new_embeddings)\n","\n","#     @add_start_docstrings_to_model_forward(DEBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n","#     @add_code_sample_docstrings(\n","#         checkpoint=_CHECKPOINT_FOR_DOC,\n","#         output_type=MultipleChoiceModelOutput,\n","#         config_class=_CONFIG_FOR_DOC,\n","#     )\n","    def forward(\n","        self,\n","        input_ids: Optional[torch.Tensor] = None,\n","        attention_mask: Optional[torch.Tensor] = None,\n","        token_type_ids: Optional[torch.Tensor] = None,\n","        position_ids: Optional[torch.Tensor] = None,\n","        inputs_embeds: Optional[torch.Tensor] = None,\n","        labels: Optional[torch.Tensor] = None,\n","        output_attentions: Optional[bool] = None,\n","        output_hidden_states: Optional[bool] = None,\n","        return_dict: Optional[bool] = None,\n","    ) -> Union[Tuple, MultipleChoiceModelOutput]:\n","        r\"\"\"\n","        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n","            Labels for computing the multiple choice classification loss. Indices should be in `[0, ...,\n","            num_choices-1]` where `num_choices` is the size of the second dimension of the input tensors. (See\n","            `input_ids` above)\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","        num_choices = input_ids.shape[1] if input_ids is not None else inputs_embeds.shape[1]\n","\n","        flat_input_ids = input_ids.view(-1, input_ids.size(-1)) if input_ids is not None else None\n","        flat_position_ids = position_ids.view(-1, position_ids.size(-1)) if position_ids is not None else None\n","        flat_token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1)) if token_type_ids is not None else None\n","        flat_attention_mask = attention_mask.view(-1, attention_mask.size(-1)) if attention_mask is not None else None\n","        flat_inputs_embeds = (\n","            inputs_embeds.view(-1, inputs_embeds.size(-2), inputs_embeds.size(-1))\n","            if inputs_embeds is not None\n","            else None\n","        )\n","\n","        outputs = self.deberta(\n","            flat_input_ids,\n","            position_ids=flat_position_ids,\n","            token_type_ids=flat_token_type_ids,\n","            attention_mask=flat_attention_mask,\n","            inputs_embeds=flat_inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        encoder_layer = outputs[0]\n","        pooled_output = self.pooler(encoder_layer)\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","\n","        reshaped_logits = logits.view(-1, num_choices)\n","\n","        kl_outputs = self.deberta(\n","            flat_input_ids,\n","            position_ids=flat_position_ids,\n","            token_type_ids=flat_token_type_ids,\n","            attention_mask=flat_attention_mask,\n","            inputs_embeds=flat_inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        kl_output = kl_outputs[0]\n","        pooled_output = self.pooler(kl_output)\n","        pooled_output = self.dropout(pooled_output)\n","        kl_logits = self.classifier(pooled_output)\n","\n","        reshaped_logits_kl = kl_logits.view(-1, num_choices)\n","        loss = None\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(reshaped_logits, labels)\n","            ce_loss = loss_fct(reshaped_logits_kl, labels)\n","            kl_loss = (KL(logits, kl_logits, \"sum\") + KL(kl_logits, logits, \"sum\")) / 2.\n","            focal_loss_fct = FocalLoss()\n","            focal_loss = focal_loss_fct(reshaped_logits, labels)\n","            total_loss = loss + ce_loss + kl_loss + focal_loss\n","        if not return_dict:\n","            output = (reshaped_logits,) + outputs[1:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return MultipleChoiceModelOutput(\n","            loss=loss,\n","            logits=reshaped_logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3574,"status":"ok","timestamp":1707404611026,"user":{"displayName":"Jie Wang","userId":"07776956424612082570"},"user_tz":-480},"id":"RCa0F1x4x1kn"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import datasets\n","from sklearn.model_selection import train_test_split\n","\n","from transformers import Trainer, TrainingArguments\n","import os\n","import sys\n","import logging\n","from transformers import AutoTokenizer,DataCollatorWithPadding,DebertaV2Tokenizer\n","import torch\n","\n","SP_train=np.load('/content/WP-train.npy',allow_pickle=True)\n","SP_test=np.load('/content/WP_new_test.npy',allow_pickle=True)\n","\n","def deal(examples):\n","    key=examples[0].keys()\n","    question=[]\n","    choice_list=[]\n","    label=[]\n","    for i in range(len(examples)):\n","        if 'label' in key:\n","            label.append(int(examples[i]['label']))\n","        question.append(examples[i]['question'])\n","        choice_list.append(examples[i]['choice_list'])\n","    if 'label' in key:\n","        data_dict={'question':question,'choice_list':choice_list,'label':label}\n","    else:\n","        data_dict={'question':question,'choice_list':choice_list}\n","    return data_dict\n","def preprocess_function(examples):\n","    inputs=[]\n","    for i in range(len(examples['question'])):\n","        encodings=tokenizer([examples['question'][i]]*4, examples['choice_list'][i],\n","                            truncation=True,padding='max_length',max_length=96,return_tensors=\"pt\")\n","        inputs.append(encodings)\n","    input_ids = torch.stack([x['input_ids'] for x in inputs])\n","    attention_mask = torch.stack([x['attention_mask'] for x in inputs])\n","    token_type_ids = torch.stack([x['token_type_ids'] for x in inputs])\n","    return {'input_ids':input_ids,'attention_mask':attention_mask,'token_type_ids':token_type_ids}\n","train_dict=deal(SP_train)\n","test_dict=deal(SP_test)\n","train, val = train_test_split(pd.DataFrame(train_dict), test_size=.2)\n","train=train.to_dict('list')\n","val=val.to_dict('list')\n","train_dataset = datasets.Dataset.from_dict(train)\n","val_dataset = datasets.Dataset.from_dict(val)\n","test_dataset=datasets.Dataset.from_dict(test_dict)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1707404611027,"user":{"displayName":"Jie Wang","userId":"07776956424612082570"},"user_tz":-480},"id":"zpMn_TRfhx4a"},"outputs":[],"source":["# import numpy as np\n","# import pandas as pd\n","# import datasets\n","# from sklearn.model_selection import train_test_split\n","# from transformers import AutoTokenizer, BertForMultipleChoice,DataCollatorWithPadding\n","# from transformers import Trainer, TrainingArguments\n","# import os\n","# import sys\n","# import logging\n","# import torch\n","# SP_train=pd.read_csv('/content/SP_train_translation.csv')\n","# SP_test=pd.read_csv('/content/SP_test_translation.csv')\n","# SP_train=SP_train.drop(columns='Unnamed: 0')\n","# SP_test=SP_test.drop(columns='Unnamed: 0')\n","# def create_choice_list(data):\n","#     choice_list=[]\n","#     for i in range(len(data['question'])):\n","#         choice_list.append([data['A'][i],data['B'][i],data['C'][i],data['D'][i]])\n","#     return choice_list\n","# SP_train['choice_list']=create_choice_list(SP_train)\n","# SP_test['choice_list']=create_choice_list(SP_test)\n","# SP_train=SP_train.drop(columns=['A','B','C','D'])\n","# SP_test=SP_test.drop(columns=['A','B','C','D'])\n","\n","# train, val = train_test_split(pd.DataFrame(SP_train), test_size=.2)\n","# train=train.to_dict('list')\n","# val=val.to_dict('list')\n","# test_dict=SP_test.to_dict('list')\n","# train_dataset = datasets.Dataset.from_dict(train)\n","# val_dataset = datasets.Dataset.from_dict(val)\n","# test_dataset=datasets.Dataset.from_dict(test_dict)\n","\n","# def preprocess_function(examples):\n","#     prompts=[]\n","#     inputs=[]\n","#     for i in range(len(examples['question'])):\n","#         encodings=tokenizer([examples['question'][i]]*4, examples['choice_list'][i],\n","#                             truncation=True,padding='max_length',max_length=96,return_tensors=\"pt\")\n","#         inputs.append(encodings)\n","#     input_ids = torch.stack([x['input_ids'] for x in inputs])\n","#     attention_mask = torch.stack([x['attention_mask'] for x in inputs])\n","#     token_type_ids = torch.stack([x['token_type_ids'] for x in inputs])\n","#     return {'input_ids':input_ids,'attention_mask':attention_mask,'token_type_ids':token_type_ids}"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1707404611027,"user":{"displayName":"Jie Wang","userId":"07776956424612082570"},"user_tz":-480},"id":"3NW5eviQyIoe"},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels.flatten(), preds.flatten(), average='weighted', zero_division=0)\n","    return {\n","        'accuracy': (preds == eval_pred.label_ids).mean(),\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","\n","# def compute_metrics(eval_pred):\n","#     logits, labels = eval_pred\n","#     predictions = np.argmax(logits, axis=-1)\n","#     return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":344,"referenced_widgets":["d7beaed7548144c4b9c2f9a6a81825af","d09624f3d7da448c9306905c856af4a3","b8b9bd87bd634506bd752ef802a4a13c","3264fc25768c47fa80caf72b16ffa3c7","3a1dbeab046f4b438fde92b5fddf241f","82dfe0bf63ac4f10a61fc588afbdbaab","100c222a5c3f4f018f6da61b1e8efd21","59654966507a4b00b6d91fcb07e84d45","ce307b90e8394c82b054086d8ae3f1c5","5994f15b3f154a06a0e1bd006abb79db","c0635fd6101449c1b58b1968c8ffaa00","a827ce5634cc4b9684d29a5755868743","561dcbf4fdce4d719fb23a3716314a2f","c97cc1305f5041d099dfdd5a8f95e86b","b537e70d0dff43838fcbac25d1f9fb30","965a45f673dc4412a6e8e8a641a2abdb","7777384d5a534bb68b41d6c3942ac172","1ea4f9446d1f488bb46f6db8af2c184d","5a6e8270f054492494fcef05b4410cb8","7db90834531649009b971b6fd5a0b6bd","0bcef0be455e47f2a0d88277fcd6a43f","2e9373295464493482f9d475be21e8f2","4bec27fc1ffb426f89dd19619e48df45","0818fee8ec414257ac15f0c68cb19e7a","ec1049e6d81c4620b9e3ff872843aa00","db80029f93664d7b89460f710d9fff3d","b4db892c50d44302adc68438a8d8ce98","50085b2bc4274523bffd87c763526f5b","e199ffcde2fd450b965e501aeef04af5","74799f8b45c04b8ea30c2f90ee86726f","7b00a0a5338c47a6b03f20d9847a3ed8","4d89ccb386254a7bbd968fa59e8629bd","15318faa213747e3ab98868db4ce11e7","d10799835d174347ac78767eb0ac3d8b","a4bf21d16e0b499aba097d0460e93bdd","9d958743926f41dbb38dea622baaa812","f04c4fa9e6c942b1aaab2613e49efe5c","6506cdf598524898a6c47edc98509678","d9098d1e88ae41a09f20fd02e107995d","e6750445d7d340aea88364f01a3e3d50","91c9fdabeacc4163a6201bfe69df36e6","18b72f65331745e880b8a595d3ed8618","f422c758b9104c369d81afd5648fd479","92101599b97f4b91974677c9c69ad4b9","95f9bce329744e74ae2dce03557cf13d","c029ab362341488a857cc0444e747ec5","a8e9b9715192486b9c6a795a92036a1d","c9d7b4313b764ac98ddedc7f0a13e56c","61d945b0f7e04a5e92a493e1e1907961","e072e129918240b9a8a896ee401509eb","bef9a233d40a464ebf2a59a5780d5dc3","dcb5800881ba4a60b4d9a823b076f158","2109b044b5c042ee8f8fd6f0cc8e72ef","be4ffb631ea04e0eb33cd06215f95815","6a701cbc92d044649f0360e9ae237f23"]},"id":"0VTonIn8yIru","outputId":"26d4f2c1-0786-4d2e-8028-8e289375d618","executionInfo":{"status":"ok","timestamp":1707404651154,"user_tz":-480,"elapsed":40150,"user":{"displayName":"Jie Wang","userId":"07776956424612082570"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7beaed7548144c4b9c2f9a6a81825af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/633 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a827ce5634cc4b9684d29a5755868743"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spm.model:   0%|          | 0.00/2.45M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bec27fc1ffb426f89dd19619e48df45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/3.14G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d10799835d174347ac78767eb0ac3d8b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v2-xxlarge and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95f9bce329744e74ae2dce03557cf13d"}},"metadata":{}}],"source":["from sklearn.metrics import precision_recall_fscore_support\n","import warnings\n","from transformers import AutoTokenizer\n","import evaluate\n","warnings.filterwarnings('ignore')\n","check_point=\"microsoft/deberta-v2-xxlarge\"\n","tokenizer = AutoTokenizer.from_pretrained(check_point)\n","model = DebertaV2ForMultipleChoice.from_pretrained(check_point)\n","\n","tokenized_train = preprocess_function(train_dataset)\n","tokenized_val = preprocess_function(val_dataset)\n","tokenized_test = preprocess_function(test_dataset)\n","labels01=torch.Tensor(train_dataset['label']).cuda()\n","labels02=torch.Tensor(val_dataset['label']).cuda()\n","tokenized_train['label']=labels01.int()\n","tokenized_val['label']=labels02.int()\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","metric = evaluate.load(\"accuracy\")"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"H1o57Zo1yIuy","executionInfo":{"status":"ok","timestamp":1707404653258,"user_tz":-480,"elapsed":2145,"user":{"displayName":"Jie Wang","userId":"07776956424612082570"}}},"outputs":[],"source":["training_args = TrainingArguments(\n","        output_dir='./checkpoint',  # output directory\n","        num_train_epochs=5,  # total number of training epochs\n","        per_device_train_batch_size=1,  # batch size per device during training\n","        per_device_eval_batch_size=1,  # batch size for evaluation\n","        warmup_steps=500,  # number of warmup steps for learning rate scheduler\n","        weight_decay=0.01,  # strength of weight decay\n","        logging_dir='./logs',  # directory for storing logs\n","        logging_steps=100,\n","        save_strategy='epoch',\n","        evaluation_strategy=\"epoch\",\n","        learning_rate=5e-5,\n","        fp16=True,\n","        remove_unused_columns=False,\n","        #load_best_model_at_end=True\n","\n",")\n","\n","trainer = Trainer(\n","        model=model,  # the instantiated 🤗 Transformers model to be trained\n","        args=training_args,  # training arguments, defined above\n","        train_dataset=datasets.Dataset.from_dict(tokenized_train),  # training dataset\n","        eval_dataset=datasets.Dataset.from_dict(tokenized_val),  # evaluation dataset\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","        compute_metrics=compute_metrics,\n","    )"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"id":"Z1LpPrkryIxv","executionInfo":{"status":"ok","timestamp":1707405954197,"user_tz":-480,"elapsed":1300952,"user":{"displayName":"Jie Wang","userId":"07776956424612082570"}},"outputId":"b6fdf00b-c2e4-4e34-fc62-5873e87d6ffa"},"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1580' max='1580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1580/1580 21:22, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.365000</td>\n","      <td>1.386218</td>\n","      <td>0.400000</td>\n","      <td>0.379400</td>\n","      <td>0.613509</td>\n","      <td>0.400000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.443300</td>\n","      <td>1.386182</td>\n","      <td>0.350000</td>\n","      <td>0.305802</td>\n","      <td>0.467011</td>\n","      <td>0.350000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.399800</td>\n","      <td>1.386414</td>\n","      <td>0.300000</td>\n","      <td>0.309913</td>\n","      <td>0.366647</td>\n","      <td>0.300000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.387400</td>\n","      <td>1.386475</td>\n","      <td>0.237500</td>\n","      <td>0.268048</td>\n","      <td>0.308122</td>\n","      <td>0.237500</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.428700</td>\n","      <td>1.386707</td>\n","      <td>0.287500</td>\n","      <td>0.144529</td>\n","      <td>0.277564</td>\n","      <td>0.287500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [80/80 00:15]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 1.3867065906524658, 'eval_accuracy': 0.2875, 'eval_f1': 0.1445294117647059, 'eval_precision': 0.2775641025641026, 'eval_recall': 0.2875, 'eval_runtime': 15.9523, 'eval_samples_per_second': 5.015, 'eval_steps_per_second': 5.015, 'epoch': 5.0}\n"]}],"source":["import torch.nn.functional as F\n","trainer.train()\n","print(trainer.evaluate())\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"BTb8KWXNy1F6","executionInfo":{"status":"ok","timestamp":1707405972368,"user_tz":-480,"elapsed":18198,"user":{"displayName":"Jie Wang","userId":"07776956424612082570"}},"colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"1279d595-b9e4-4a22-e370-8843a8bc6b95"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"]}],"source":["prediction_outputs = trainer.predict(datasets.Dataset.from_dict(tokenized_test))\n","test_pred = np.argmax(prediction_outputs[0], axis=-1).flatten()\n","print(test_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EbSO7jQic562"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyPgiBQ7ZXBuJW7/NMKACeu7"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d7beaed7548144c4b9c2f9a6a81825af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d09624f3d7da448c9306905c856af4a3","IPY_MODEL_b8b9bd87bd634506bd752ef802a4a13c","IPY_MODEL_3264fc25768c47fa80caf72b16ffa3c7"],"layout":"IPY_MODEL_3a1dbeab046f4b438fde92b5fddf241f"}},"d09624f3d7da448c9306905c856af4a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82dfe0bf63ac4f10a61fc588afbdbaab","placeholder":"​","style":"IPY_MODEL_100c222a5c3f4f018f6da61b1e8efd21","value":"tokenizer_config.json: 100%"}},"b8b9bd87bd634506bd752ef802a4a13c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_59654966507a4b00b6d91fcb07e84d45","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce307b90e8394c82b054086d8ae3f1c5","value":52}},"3264fc25768c47fa80caf72b16ffa3c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5994f15b3f154a06a0e1bd006abb79db","placeholder":"​","style":"IPY_MODEL_c0635fd6101449c1b58b1968c8ffaa00","value":" 52.0/52.0 [00:00&lt;00:00, 3.09kB/s]"}},"3a1dbeab046f4b438fde92b5fddf241f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82dfe0bf63ac4f10a61fc588afbdbaab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"100c222a5c3f4f018f6da61b1e8efd21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59654966507a4b00b6d91fcb07e84d45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce307b90e8394c82b054086d8ae3f1c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5994f15b3f154a06a0e1bd006abb79db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0635fd6101449c1b58b1968c8ffaa00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a827ce5634cc4b9684d29a5755868743":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_561dcbf4fdce4d719fb23a3716314a2f","IPY_MODEL_c97cc1305f5041d099dfdd5a8f95e86b","IPY_MODEL_b537e70d0dff43838fcbac25d1f9fb30"],"layout":"IPY_MODEL_965a45f673dc4412a6e8e8a641a2abdb"}},"561dcbf4fdce4d719fb23a3716314a2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7777384d5a534bb68b41d6c3942ac172","placeholder":"​","style":"IPY_MODEL_1ea4f9446d1f488bb46f6db8af2c184d","value":"config.json: 100%"}},"c97cc1305f5041d099dfdd5a8f95e86b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a6e8270f054492494fcef05b4410cb8","max":633,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7db90834531649009b971b6fd5a0b6bd","value":633}},"b537e70d0dff43838fcbac25d1f9fb30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bcef0be455e47f2a0d88277fcd6a43f","placeholder":"​","style":"IPY_MODEL_2e9373295464493482f9d475be21e8f2","value":" 633/633 [00:00&lt;00:00, 57.3kB/s]"}},"965a45f673dc4412a6e8e8a641a2abdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7777384d5a534bb68b41d6c3942ac172":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ea4f9446d1f488bb46f6db8af2c184d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a6e8270f054492494fcef05b4410cb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7db90834531649009b971b6fd5a0b6bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0bcef0be455e47f2a0d88277fcd6a43f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e9373295464493482f9d475be21e8f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bec27fc1ffb426f89dd19619e48df45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0818fee8ec414257ac15f0c68cb19e7a","IPY_MODEL_ec1049e6d81c4620b9e3ff872843aa00","IPY_MODEL_db80029f93664d7b89460f710d9fff3d"],"layout":"IPY_MODEL_b4db892c50d44302adc68438a8d8ce98"}},"0818fee8ec414257ac15f0c68cb19e7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50085b2bc4274523bffd87c763526f5b","placeholder":"​","style":"IPY_MODEL_e199ffcde2fd450b965e501aeef04af5","value":"spm.model: 100%"}},"ec1049e6d81c4620b9e3ff872843aa00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_74799f8b45c04b8ea30c2f90ee86726f","max":2447305,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b00a0a5338c47a6b03f20d9847a3ed8","value":2447305}},"db80029f93664d7b89460f710d9fff3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d89ccb386254a7bbd968fa59e8629bd","placeholder":"​","style":"IPY_MODEL_15318faa213747e3ab98868db4ce11e7","value":" 2.45M/2.45M [00:00&lt;00:00, 24.3MB/s]"}},"b4db892c50d44302adc68438a8d8ce98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50085b2bc4274523bffd87c763526f5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e199ffcde2fd450b965e501aeef04af5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74799f8b45c04b8ea30c2f90ee86726f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b00a0a5338c47a6b03f20d9847a3ed8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d89ccb386254a7bbd968fa59e8629bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15318faa213747e3ab98868db4ce11e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d10799835d174347ac78767eb0ac3d8b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4bf21d16e0b499aba097d0460e93bdd","IPY_MODEL_9d958743926f41dbb38dea622baaa812","IPY_MODEL_f04c4fa9e6c942b1aaab2613e49efe5c"],"layout":"IPY_MODEL_6506cdf598524898a6c47edc98509678"}},"a4bf21d16e0b499aba097d0460e93bdd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9098d1e88ae41a09f20fd02e107995d","placeholder":"​","style":"IPY_MODEL_e6750445d7d340aea88364f01a3e3d50","value":"pytorch_model.bin: 100%"}},"9d958743926f41dbb38dea622baaa812":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_91c9fdabeacc4163a6201bfe69df36e6","max":3135788407,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18b72f65331745e880b8a595d3ed8618","value":3135788407}},"f04c4fa9e6c942b1aaab2613e49efe5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f422c758b9104c369d81afd5648fd479","placeholder":"​","style":"IPY_MODEL_92101599b97f4b91974677c9c69ad4b9","value":" 3.14G/3.14G [00:17&lt;00:00, 204MB/s]"}},"6506cdf598524898a6c47edc98509678":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9098d1e88ae41a09f20fd02e107995d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6750445d7d340aea88364f01a3e3d50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91c9fdabeacc4163a6201bfe69df36e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18b72f65331745e880b8a595d3ed8618":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f422c758b9104c369d81afd5648fd479":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92101599b97f4b91974677c9c69ad4b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95f9bce329744e74ae2dce03557cf13d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c029ab362341488a857cc0444e747ec5","IPY_MODEL_a8e9b9715192486b9c6a795a92036a1d","IPY_MODEL_c9d7b4313b764ac98ddedc7f0a13e56c"],"layout":"IPY_MODEL_61d945b0f7e04a5e92a493e1e1907961"}},"c029ab362341488a857cc0444e747ec5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e072e129918240b9a8a896ee401509eb","placeholder":"​","style":"IPY_MODEL_bef9a233d40a464ebf2a59a5780d5dc3","value":"Downloading builder script: 100%"}},"a8e9b9715192486b9c6a795a92036a1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcb5800881ba4a60b4d9a823b076f158","max":4203,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2109b044b5c042ee8f8fd6f0cc8e72ef","value":4203}},"c9d7b4313b764ac98ddedc7f0a13e56c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be4ffb631ea04e0eb33cd06215f95815","placeholder":"​","style":"IPY_MODEL_6a701cbc92d044649f0360e9ae237f23","value":" 4.20k/4.20k [00:00&lt;00:00, 298kB/s]"}},"61d945b0f7e04a5e92a493e1e1907961":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e072e129918240b9a8a896ee401509eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bef9a233d40a464ebf2a59a5780d5dc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcb5800881ba4a60b4d9a823b076f158":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2109b044b5c042ee8f8fd6f0cc8e72ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be4ffb631ea04e0eb33cd06215f95815":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a701cbc92d044649f0360e9ae237f23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}